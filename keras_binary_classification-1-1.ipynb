{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (Feed-Forward Network / Artificial Neural Network)\n",
    "In this notebook we will cover the use of Keras for creating a very small neural network (MLP) to solve a binary classification problem. This is the simplest form of *supervised machine learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "Uncomment the appropriate lines to install the packages. We will most likely be re-running this notebook several times, so you may wish to comment them again after installation (or use pip from command prompt).\n",
    "\n",
    "Packages needed for this workshop:\n",
    "- Keras\n",
    "- Tensorflow\n",
    "- Numpy\n",
    "- Scikit-learn\n",
    "- Pandas\n",
    "\n",
    "Keras is built on top of Tensorflow. Scikit-learn is a library which focuses on machine learning algorithms and techniques, we will be using some utility functions from this. Pandas is a Data Science framework for wrangling data and dealing with large volumes in a nicer way; manually processing records and columns is a chore, this makes things simpler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Our main imports will be `tensorflow`, and `keras`. Just like with `numpy`, we often make use of aliases when importing `tensorflow` to make life easier.\n",
    "\n",
    "One of the more useful imports we want to have is `from tensorflow.keras import layers`, this allows us to quickly define layers of our neural network.\n",
    "E.g `layers.Dense(N)` for a single layer containing N of fully-connected perceptrons to/from surrounding layers.\n",
    "\n",
    "*Note*: the layers import is strictly for convenience. We can access everything from the top-level module, tensorflow. `layers.Dense()` is equivalent to `tensorflow.keras.layers.Dense()`, but writing that everytime can make code confusing and hurt readability. Code readability is key to good software for you and your team.\n",
    "\n",
    "When importing tensorflow, you may see some output related to cuda if you have a supported GPU. Tensorflow will automatically run on the GPU if supported, otherwise it will be on the CPU only. GPU acceleration is a huge part in why modern machine learning is so popular, performant, and efficient.\n",
    "\n",
    "Here, we will use the `__version__` meta-attribute to check the version of both the base tensorflow library, and the keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these later, best to import them up here.\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing some Data - Wine Quality Classification\n",
    "\n",
    "Before we can define our model, we first need to determine what our input is. What is the task we are trying to solve? What features are we looking at?\n",
    "\n",
    "For this activity we're going to be looking at a simple dataset to get started. We're going to be looking at a cleaned and already preprocessed dataset from the UCI Machine Learning Repository. These data include 11 input features of various qualities of wine. Our task is to classify the wine as \"good\" or \"bad\". These classifications were derived from wine tasting scores. (Bhat, 2020)\n",
    "\n",
    "Make sure you download the `wine.csv` file from Canvas. Put this in the same folder as your `.ipynb` notebook.\n",
    "\n",
    "Bhat, N. (2020) “Wine Quality Classification.” Available at: https://www.kaggle.com/nareshbhat/wine-quality-binary-classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file format is in that of a `.csv` file. A **comma seperated value** file. Each row represents a separate patient records, and our columns (features) are separated by `,`.\n",
    "\n",
    "For our Data Description we have the following information from Bhat (2020).\n",
    "\n",
    "Input variables (based on physicochemical tests):\n",
    "\n",
    "1. fixed acidity\n",
    "2. volatile acidity\n",
    "3. citric acid\n",
    "4. residual sugar\n",
    "5. chlorides\n",
    "6. free sulfur dioxide\n",
    "7. total sulfur dioxide\n",
    "8. density\n",
    "9. pH\n",
    "10. sulphates\n",
    "11. alcohol\n",
    "\n",
    "Output variable (based on sensory data):\n",
    "\n",
    "12. quality ('good' and 'bad' based on score >5 and <5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to import pandas as pd somewhere in your file (we did this at the top)\n",
    "\n",
    "# We can tell Pandas to read our CSV data file by giving it a file path.\n",
    "training_data = pd.read_csv('./wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol quality  \n",
       "0         9.4     bad  \n",
       "1         9.8     bad  \n",
       "2         9.8     bad  \n",
       "3         9.8    good  \n",
       "4         9.4     bad  \n",
       "...       ...     ...  \n",
       "1594     10.5     bad  \n",
       "1595     11.2    good  \n",
       "1596     11.0    good  \n",
       "1597     10.2     bad  \n",
       "1598     11.0    good  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Pre-processing\n",
    "\n",
    "At the moment, our target variable (our last column), is mixed in with the rest of our data, and it's in the wrong format. We need to change bad -> 0, good -> 1.\n",
    "\n",
    "Then we want to separate it into our input data (the features), and our target variable ( the thing we want to predict )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the quality column, and then remove it from the main Dataframe.\n",
    "training_y = training_data.pop('quality')\n",
    "\n",
    "# Data needs to be numeric for us to work with it.\n",
    "# We can use dataframe.replace to replace values with others.\n",
    "# In this case, we'll replace \"good\" with 1, as we're making a good quality wine classifier.\n",
    "#\n",
    "# inplace=True means we don't need to assign it to a new variable.\n",
    "training_y.replace(\"good\", 1, inplace=True)\n",
    "training_y.replace(\"bad\", 0, inplace=True)\n",
    "\n",
    "# This means training_data is left with the rest of the data.\n",
    "# TODO: You can use training_data[[\"colA\",\"colB\",\"colC\"]] etc to specify the names of columsn.\n",
    "# E.g training_data[[\"citric acid\", \"chloriddes\"]] would grab only those columns for citric acid, and chlorides from the dataframe.\n",
    "# Note: training_data[\"single column\"] for grabbing just one column.\n",
    "#       training_data[[\"firstColumn\", \"secondColumn\"]] if we want multiple columns.\n",
    "# [] vs [[]]\n",
    "\n",
    "training_x = training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "1594    0\n",
       "1595    1\n",
       "1596    1\n",
       "1597    0\n",
       "1598    1\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Pandas DataFrame into a Numpy Array\n",
    "\n",
    "If we try and pass our Pandas DataFrame (and all its magical properties) to our Keras neural network, it will most likely error. Once we're done with pre-processing and using Pandas utilities, we can convert the dataframe ready for input into the Neural Network. *These networks really are quite picky!*\n",
    "\n",
    "I will define some new variables `arr_train_x` and `arr_train_y`, but you can override variable names if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train_x = training_x.to_numpy()\n",
    "arr_train_y = training_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.4    0.7    0.    ...  3.51   0.56   9.4  ]\n",
      " [ 7.8    0.88   0.    ...  3.2    0.68   9.8  ]\n",
      " [ 7.8    0.76   0.04  ...  3.26   0.65   9.8  ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  3.42   0.75  11.   ]\n",
      " [ 5.9    0.645  0.12  ...  3.57   0.71  10.2  ]\n",
      " [ 6.     0.31   0.47  ...  3.39   0.66  11.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(arr_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Model\n",
    "\n",
    "Usually Keras model definition is wrapped in a user-defined function. However, for the purposes of this small network, this is unnecessary.\n",
    "\n",
    "Today we will be using the *Sequential API* for model definition. This is for straight-forward networks which are built layer-by-layer. For more complex networks, the *Functional API* is required (multi-input, multi-output, etc).\n",
    "\n",
    "We define a new Sequential model, this will be empty. From this we can sequentially add layers, starting from the input and working towards our output.\n",
    "\n",
    "The `layers.InputLayer` has a number of parameters we can provide it. Most importantly this will be the expected input shape. As we have already looked at the data we wish to pass this network, we know that we have 11 features (fixed acidity, volatile acidity, ..., sulphates), and the target variable (Wine Quality). Therefore, the input shape to our network is `(11)`.\n",
    "*Note*: We need to ensure the shape is a `tuple`. E.g `(1, 2, 3)` using parenthese. This is because our input shape can get quite complex and multi-dimensional. E.g `(224,224,3)` is an example from Computer Vision for a single colour image.\n",
    "\n",
    "Once we've defined all of our layers, we can run `model.summary()` and this will print out a list of our layers, their output shape, and how many tunable parameters (the thing which needs to be learned!) there are. The great thing about Keras is that all the calculations for shapes of all your vectors/matrices is done for you. You specify how many nodes per layer, and Keras does the rest. *This is certainly quicker than how we used to have to calculate this by hand!*\n",
    "\n",
    "*Note*: You may see lots of output after our table from Keras/Tensorflow. This is most likely GPU finding. These models we're defining are graphs. These graphs go onto the CPU/GPU ready to be fed with data.\n",
    "\n",
    "For this network we have our 11 input features, then a layer of **32** perceptrons (fully-connected to each input), the output of each of these hidden layer perceptrons is then fully-connected to the next layer, a layer of **1** perceptron (our output). For our hidden layer, the activation function is selected to be `relu`. Our final layer is the `sigmoid` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11)\n",
      "(1599,)\n"
     ]
    }
   ],
   "source": [
    "print(arr_train_x.shape)\n",
    "print(arr_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(11))) # 11 Columns of input\n",
    "\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\")) # 0->1 floating\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling our Model\n",
    "\n",
    "We have just defined our model, and the layers it has. However, this isn't everything. For a model to be trainable we need to define a loss function. I.e How do we calculate the difference between the network's output and the ground truth output (what it should be).\n",
    "\n",
    "In our reading, we introduced this as the concept related to the distance squared between two real numbers. However, we're working with categories in our outputs here. We either have good wine, or bad wine. This is known as **binary classification**\n",
    "\n",
    "For our optimiser, we will use **Stochastic Gradient Descent**; later on we will explore other optimiser, but let's keep the classic `sgd`.\n",
    "We can tell Keras to automatically log some metrics. `accuracy` is one which it understands by default (A list can be found https://keras.io/api/metrics/accuracy_metrics/#binaryaccuracy-class)\n",
    "\n",
    "### Loss Function\n",
    "For this we are using `binary_crossentropy`. It's as simple as stating it as a string.\n",
    "\n",
    "$$\n",
    "H_{p}(q) = -\\frac{1}{N}\\sum_{i=1}^{N}y_{i}\\cdot log(p(y_{i})) + (1-y_{i})\\cdot log(1-p(y_{i}))\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "y_{i}\\cdot log(p(y_{i}))\n",
    "$$\n",
    "If $y_{i}$ is 0, then this whole terms goes to 0. Conversely:\n",
    "\n",
    "$$\n",
    "(1-y_{i})\\cdot log(1-p(y_{i})\n",
    "$$\n",
    "If $y_{i}$ is 1 (the other class), then this term goes to zero because of the $(1-y_{i})$.\n",
    "\n",
    "Therefore, when we look at this equation, we either have the left side of the $+$, of the right side. In either case we are simply taking the `log()` of the class output. Hence why binary crossentropy is often refered to as the log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting our model\n",
    "\n",
    "We have our model architecture defined. We have compiled it, providing the loss definition, the optimiser, and any metrics we wish to log. Now comes the time to train our model.\n",
    "\n",
    "We provide the model with both the input data and the ground truth data for the target variable. From this, using the loss function, it will adjust its parameters (weights) to minimise the loss function.\n",
    "\n",
    "An important parameter to provide when training is the number of epochs. An `epoch` is defined as a single iteration through the whole input dataset. E.g If we have 500 records, then 1 epoch is when all 500 records have been through the network (and backprop for learning). After a single epoch our network may not have learned the problem perfectly, so we can repeat over many epochs, gradually improving our network. At a certain stage, we will hit some limitation where more examples do not improve the network. We will have stagnated, and training should stop.\n",
    "\n",
    "For now, we are going to set this to an initial value of 50. We can modify this later to see what happens.\n",
    "Provide your `training_x` and `training_y` data to the fit function. X first, labels second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_history = model.fit(\n",
    "    arr_train_x,\n",
    "    arr_train_y,\n",
    "    epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our Model\n",
    "### Plotting Loss and Accuracy curves using History\n",
    "\n",
    "When fitting our Keras model, we can get a `History` object back out. This contains the metrics for loss for each epoch, as well as any additional metrics we defined (such as accuracy).\n",
    "\n",
    "If we `print(model_training_history.history.keys())` we can see what's available to us. This is because our rich History object (we called it model_training_history), has a dictionary inside (called history). If we get all the keys to that dictionary we can see the metrics it's stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(model_training_history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a library called Matplotlib to help us graph these metrics per epoch. This will provide us an idea of how our model was during training, and can help us determine what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If we want to be fancy, we can set a theme by uncommenting the below line.\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "# Set up a figure, and two handles for our 2 figures.\n",
    "# Subplot can make many many plots within a single figure.\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "# Get our accuracy and loss metrics (these should be lists of numbers)\n",
    "acc = model_training_history.history['accuracy']\n",
    "loss = model_training_history.history['loss']\n",
    "\n",
    "# We want accuracy on our first graph\n",
    "ax1.plot(acc)\n",
    "# Loss on our second\n",
    "ax2.plot(loss)\n",
    "    \n",
    "# Give our figures some x and y axis labels.\n",
    "ax1.set_ylabel('training accuracy')\n",
    "ax2.set_ylabel('training loss')\n",
    "\n",
    "# They both share an x axis, so we only need to define it on the bottom-most.\n",
    "ax2.set_xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - Good Practice: We need hold-out data. Where's the test set?\n",
    "\n",
    "We made a mistake when training our Neural Network. We used all of our data for training. Now we have a fully-trained model, but it's seen all of the data we have. We can't evaluate it purely on the training data. That would be like asking you to take an exam where we've already shown you the answers!\n",
    "\n",
    "Therefore, we should have partitioned our initial dataset into a training and a test set. We can use sklearn for this.\n",
    "\n",
    "`train_test_split` is a utility function which accepts our X data, and labels: y. It can partition (we have chosen test_size of 30%) as well as shuffle our data for us. Here we provide a `random_state` so that it will shuffle the same way everytime (deterministic) for testing purposes. In the real-world we would not leave this in.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 11)\n",
      "(480, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    arr_train_x, arr_train_y, test_size=0.3, random_state=2, shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a roughly 70-30 split for our data, as well as our labels.\n",
    "\n",
    "#### Do the following:\n",
    "\n",
    "Go back to our training procedure from before, and insert this train_test_split functionality before we get to training our model. Re-run your experiment using the <u>training set</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Evaluation Metrics\n",
    "\n",
    "In this week's reading we looked at some evaluation metrics for classification tasks, including the confusion matrix. Sklearn has some functionality for `classification_report` and `confusion_matrix` which we can use.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "```\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "We can use `model.evaluate(test_x, test_y)` to run through our test set and provide some loss and accuracy metrics.\n",
    "\n",
    "Additional, we can introduce `model.predict()` and provide input data to the model. This will run a forward pass on the data to obtain the network's estimate. This is called *inference*. Once we have all the predicted y values, we can run our own metric calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 666us/step - loss: 0.6137 - accuracy: 0.6604\n",
      "0.6136506795883179 0.6604166626930237\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106  87]\n",
      " [ 76 211]]\n",
      "TP: 211\n",
      "FP: 87\n",
      "TN: 106\n",
      "FN: 76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ground truth Y data, predicted Y data.\n",
    "# We have to threshold our network ourselves currently due to the sigmoid output.\n",
    "# We can interpret this output as a form of probability or confidence value. Closer to 1, the more probable.\n",
    "# We will assume that >= 0.5 is a 1, and < 0.5 is a 0.\n",
    "\n",
    "print(confusion_matrix(Y_test, np.round(y_pred) ))\n",
    "\n",
    "# We can even assign variables to the output! adding .ravel() to the conf matrix.\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, np.round(y_pred) ).ravel()\n",
    "print(f\"TP: {tp}\")\n",
    "print(f\"FP: {fp}\")\n",
    "print(f\"TN: {tn}\")\n",
    "print(f\"FN: {fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `ConfusionMatrixDisplay` utility of sklearn to visualise our matrix.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fac38102f70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate\n",
    "Calculate the Precision, Recall, and F1-Score from the TP/TN/FP/FN metrics above. **Remember**: This is for the test set only, we can call `.shape` on them to get the number of rows and features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Experimentation\n",
    "\n",
    "Go back through the code in this activity and try the following experiments:\n",
    "* Change the values for the number of hidden nodes in a single hidden layer\n",
    "* Change the number of hidden layers\n",
    "* Vary the number of neurons in both of these layers\n",
    "* Modify the Epoch numbers and observe the loss graphs.\n",
    "\n",
    "Your goal is to see the impact that these changes have on the overall accuracy, confusion matrix, precision/recall/f-1 scores. Be sure not to change too many all at once, otherwise you won't know what caused the change."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
